{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e5c3647",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# RAG Implementation - Step by Step\n",
    "\n",
    "This notebook teaches RAG (Retrieval-Augmented Generation) fundamentals through practical implementation.\n",
    "\n",
    "**What is RAG?**\n",
    "RAG combines retrieval of relevant documents with language model generation to produce answers grounded in actual data.\n",
    "\n",
    "**Steps we'll follow:**\n",
    "1. Install and import dependencies\n",
    "2. Setup vector database\n",
    "3. Load and chunk documents\n",
    "4. Create retriever\n",
    "5. Build RAG chain\n",
    "6. Test with queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11046ae8",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "## Step 1: Install Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c5ae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "\n",
    "# List of packages needed for RAG\n",
    "packages = [\n",
    "    \"langchain\",\n",
    "    \"langchain-chroma\",\n",
    "    \"langchain-openai\",\n",
    "    \"langchain-core\",\n",
    "    \"python-dotenv\",\n",
    "    \"chromadb\"\n",
    "]\n",
    "\n",
    "print(\"Installing packages...\\n\")\n",
    "\n",
    "for package in packages:\n",
    "    try:\n",
    "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "        print(f\"✓ {package}\")\n",
    "    except:\n",
    "        print(f\"✗ {package} (already installed)\")\n",
    "\n",
    "print(\"\\n✓ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd3f190",
   "metadata": {},
   "source": [
    "## Step 2: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0951b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✓ All imports successful\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de51c0cd",
   "metadata": {},
   "source": [
    "## Step 3: Initialize Embeddings Model\n",
    "\n",
    "Embeddings convert text into numerical vectors that capture semantic meaning.\n",
    "We'll use OpenAI's text-embedding-3-large model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3a36ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "print(\"✓ Embeddings model initialized\")\n",
    "print(f\"  Model: text-embedding-3-large\")\n",
    "print(f\"  Type: {type(embeddings).__name__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31ad84f",
   "metadata": {},
   "source": [
    "## Step 4: Create Vector Store (ChromaDB)\n",
    "\n",
    "ChromaDB is a lightweight vector database. It will store our document embeddings\n",
    "and allow us to search for similar documents semantically."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
