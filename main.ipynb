{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required packages...\n",
      "\n",
      "Installing langchain...\n",
      "✓ langchain installed successfully\n",
      "Installing langchain-chroma...\n",
      "✓ langchain-chroma installed successfully\n",
      "Installing langchain-openai...\n",
      "✓ langchain-openai installed successfully\n",
      "Installing langchain-core...\n",
      "✓ langchain-core installed successfully\n",
      "Installing python-dotenv...\n",
      "✓ python-dotenv installed successfully\n",
      "Installing chromadb...\n",
      "✓ chromadb installed successfully\n",
      "\n",
      "✓ All packages installed successfully!\n",
      "\n",
      "Installed packages:\n",
      "  - langchain\n",
      "  - langchain-chroma\n",
      "  - langchain-openai\n",
      "  - langchain-core\n",
      "  - python-dotenv\n",
      "  - chromadb\n"
     ]
    }
   ],
   "source": [
    "# Install all required LangChain packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    \"langchain\",\n",
    "    \"langchain-chroma\",\n",
    "    \"langchain-openai\",\n",
    "    \"langchain-core\",\n",
    "    \"python-dotenv\",\n",
    "    \"chromadb\"\n",
    "]\n",
    "\n",
    "print(\"Installing required packages...\\n\")\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"Installing {package}...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "    print(f\"✓ {package} installed successfully\")\n",
    "\n",
    "print(\"\\n✓ All packages installed successfully!\")\n",
    "print(\"\\nInstalled packages:\")\n",
    "for package in packages:\n",
    "    print(f\"  - {package}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_text_splitters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunnablePassthrough\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings, ChatOpenAI\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_text_splitters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CharacterTextSplitter\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# load .env file\u001b[39;00m\n\u001b[1;32m     11\u001b[0m load_dotenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../.env\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_text_splitters'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# load .env file\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Embeddings Model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Initialize ChromaDB as Vector Store\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"test_collection\",\n",
    "    embedding_function=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the File into LangChain Documents & Save to Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in State of the Union Address File\n",
    "with open(\"2024_state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "\n",
    "# Initialize Text Splitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# Create Documents (Chunks) From File\n",
    "texts = text_splitter.create_documents([state_of_the_union])\n",
    "\n",
    "# Save Document Chunks to Vector Store\n",
    "ids = vector_store.add_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Similarity Check with Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* And yes, my purpose tonight is to both wake up this Congress, and alert the American people that this is no ordinary moment either. \n",
      "\n",
      "Not since President Lincoln and the Civil War have freedom and democracy been under assault here at home as they are today. \n",
      "\n",
      "What makes our moment rare is that freedom and democracy are under attack, both at home and overseas, at the very same time. \n",
      "\n",
      "Overseas, Putin of Russia is on the march, invading Ukraine and sowing chaos throughout Europe and beyond. \n",
      "\n",
      "If anybody in this room thinks Putin will stop at Ukraine, I assure you, he will not. \n",
      "\n",
      "But Ukraine can stop Putin if we stand with Ukraine and provide the weapons it needs to defend itself. That is all Ukraine is asking. They are not asking for American soldiers. \n",
      "\n",
      "In fact, there are no American soldiers at war in Ukraine. And I am determined to keep it that way. \n",
      "\n",
      "But now assistance for Ukraine is being blocked by those who want us to walk away from our leadership in the world. [{}]\n",
      "\n",
      "\n",
      "* But now assistance for Ukraine is being blocked by those who want us to walk away from our leadership in the world. \n",
      "\n",
      "It wasn’t that long ago when a Republican President, Ronald Reagan, thundered, “Mr. Gorbachev, tear down this wall.” \n",
      "\n",
      "Now, my predecessor, a former Republican President, tells Putin, “Do whatever the hell you want.” \n",
      "\n",
      "A former American President actually said that, bowing down to a Russian leader. \n",
      "\n",
      "It’s outrageous. It’s dangerous. It’s unacceptable. \n",
      "\n",
      "America is a founding member of NATO the military alliance of democratic nations created after World War II to prevent war and keep the peace.  \n",
      "\n",
      "Today, we’ve made NATO stronger than ever. \n",
      "\n",
      "We welcomed Finland to the Alliance last year, and just this morning, Sweden officially joined NATO, and their Prime Minister is here tonight. \n",
      "\n",
      "Mr. Prime Minister, welcome to NATO, the strongest military alliance the world has ever known. [{}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the Vector Store\n",
    "results = vector_store.similarity_search(\n",
    "    'Who invaded Ukraine?',\n",
    "    k=2\n",
    ")\n",
    "\n",
    "# Print Resulting Chunks\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Document Parsing Function to String\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Chroma as the Retriever\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM instance\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Prompt Template\n",
    "prompt_template = \"\"\"Use the context provided to answer the user's question below. If you do not know the answer based on the context provided, tell the user that you do not know the answer to their question based on the context provided and that you are sorry.\n",
    "context: {context}\n",
    "\n",
    "question: {query}\n",
    "\n",
    "answer: \"\"\"\n",
    "\n",
    "# Create Prompt Instance from template\n",
    "custom_rag_prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RAG Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"query\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the 2024 State of the Union address, Putin of Russia invaded Ukraine.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the RAG Chain\n",
    "rag_chain.invoke(\"According to the 2024 state of the union address, Who invaded Ukraine?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I do not know the answer to your question based on the context provided.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get an I don't know from the Model\n",
    "rag_chain.invoke(\"What is the purpose of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agentic AI - Basic Starter Code\n",
    "\n",
    "This section covers foundational concepts of building AI agents step-by-step:\n",
    "1. **Tools**: Functions that agents can use\n",
    "2. **Agent**: Decision-making entity that chooses which tools to use\n",
    "3. **Tool Calling**: How agents invoke tools\n",
    "4. **Reasoning Loop**: Agent thinking and acting iteratively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Understanding Tools\n",
    "\n",
    "A **tool** is a function that an agent can call to perform specific tasks. Tools define:\n",
    "- **Name**: Identifier for the tool\n",
    "- **Description**: What the tool does (helps agent decide when to use it)\n",
    "- **Parameters**: Input schema for the tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "from typing import Union\n",
    "\n",
    "# Example Tool 1: Calculator\n",
    "@tool\n",
    "def add_numbers(a: float, b: float) -> float:\n",
    "    \"\"\"Add two numbers together. Use this for addition operations.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply_numbers(a: float, b: float) -> float:\n",
    "    \"\"\"Multiply two numbers. Use this for multiplication operations.\"\"\"\n",
    "    return a * b\n",
    "\n",
    "# Example Tool 2: Get Weather (simulated)\n",
    "@tool\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"Get the current weather for a city. Returns weather description.\"\"\"\n",
    "    # In real world, this would call a weather API\n",
    "    weather_data = {\n",
    "        \"New York\": \"Sunny, 72°F\",\n",
    "        \"London\": \"Rainy, 55°F\",\n",
    "        \"Tokyo\": \"Cloudy, 68°F\"\n",
    "    }\n",
    "    return weather_data.get(city, \"Weather data not available\")\n",
    "\n",
    "# Example Tool 3: Get Current Time (simulated)\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get the current date and time.\"\"\"\n",
    "    from datetime import datetime\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "# Create a list of tools for the agent\n",
    "tools = [add_numbers, multiply_numbers, get_weather, get_current_time]\n",
    "\n",
    "print(\"✓ Created 4 tools:\")\n",
    "print(\"  1. add_numbers(a, b) - Addition\")\n",
    "print(\"  2. multiply_numbers(a, b) - Multiplication\")\n",
    "print(\"  3. get_weather(city) - Get weather for a city\")\n",
    "print(\"  4. get_current_time() - Get current time\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Initialize the Agent\n",
    "\n",
    "An **agent** combines:\n",
    "- **LLM (Language Model)**: Makes decisions about which tools to use\n",
    "- **Tools**: The toolkit available to the agent\n",
    "- **Agent Type**: How the agent processes information and decides actions\n",
    "\n",
    "LangChain provides different agent architectures. We'll use `tool_calling` which is supported by GPT-4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import BaseMessage, HumanMessage\n",
    "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "# Define the system prompt for the agent\n",
    "# This tells the agent its role and how to behave\n",
    "system_prompt = \"\"\"You are a helpful AI assistant with access to various tools.\n",
    "When a user asks a question, analyze what they're asking and determine which tools to use.\n",
    "Use the tools available to you to answer the user's question accurately.\n",
    "Always explain your reasoning when using tools.\n",
    "Be conversational and helpful.\"\"\"\n",
    "\n",
    "# Create a prompt template with placeholders for messages\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompt),\n",
    "    MessagesPlaceholder(variable_name=\"messages\"),\n",
    "])\n",
    "\n",
    "# Initialize the LLM (we already created this earlier)\n",
    "# llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "# Bind tools to the LLM\n",
    "# This tells the LLM about the available tools\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "# Create the agent\n",
    "agent = create_tool_calling_agent(llm_with_tools, tools, prompt)\n",
    "\n",
    "# Create an AgentExecutor\n",
    "# This executes the agent's decisions in a loop\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, max_iterations=10)\n",
    "\n",
    "print(\"✓ Agent created and ready to use!\")\n",
    "print(\"\\nAgent Components:\")\n",
    "print(\"  - LLM Model: GPT-4o-mini\")\n",
    "print(\"  - Available Tools: 4 tools bound to agent\")\n",
    "print(\"  - Agent Type: Tool-calling agent\")\n",
    "print(\"  - Max Iterations: 10 (safety limit)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Agent Reasoning Loop\n",
    "\n",
    "The agent follows this loop:\n",
    "1. **Observation**: Receives user query\n",
    "2. **Thinking**: Analyzes what needs to be done\n",
    "3. **Action**: Decides which tool(s) to use\n",
    "4. **Observation**: Gets tool results\n",
    "5. **Response**: Generates answer based on results\n",
    "\n",
    "Let's see this in action with simple queries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Simple math question\n",
    "print(\"=\" * 60)\n",
    "print(\"EXAMPLE 1: Simple Math Question\")\n",
    "print(\"=\" * 60)\n",
    "result1 = agent_executor.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What is 25 multiplied by 4?\")]\n",
    "})\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(result1[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Query requiring multiple steps\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXAMPLE 2: Multi-Step Reasoning\")\n",
    "print(\"=\" * 60)\n",
    "result2 = agent_executor.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Add 10 and 5, then multiply the result by 3\")]\n",
    "})\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(result2[\"output\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3: Query using different tools\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"EXAMPLE 3: Using Different Tools\")\n",
    "print(\"=\" * 60)\n",
    "result3 = agent_executor.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"What time is it now and what's the weather in New York?\")]\n",
    "})\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(result3[\"output\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Understanding Agent Decision-Making\n",
    "\n",
    "The agent's thinking process:\n",
    "- **Perception**: Reads the user query\n",
    "- **Tool Selection**: Evaluates which tools are relevant\n",
    "- **Parameter Mapping**: Extracts correct parameters for tools\n",
    "- **Sequential Execution**: If one tool depends on another, the agent chains them\n",
    "- **Response Generation**: Synthesizes results into a natural answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see what tools the agent has available\n",
    "print(\"Available Tools Information:\\n\")\n",
    "for tool in tools:\n",
    "    print(f\"Tool Name: {tool.name}\")\n",
    "    print(f\"Description: {tool.description}\")\n",
    "    # Get the tool's parameters\n",
    "    if hasattr(tool, 'args_schema'):\n",
    "        print(f\"Parameters: {tool.args_schema}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Advanced - Creating Custom Tools\n",
    "\n",
    "You can create domain-specific tools for your use case. Here are some practical examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example: Custom tools for a customer service agent\n",
    "@tool\n",
    "def search_knowledge_base(query: str) -> str:\n",
    "    \"\"\"Search our knowledge base for relevant articles and documentation.\"\"\"\n",
    "    # Simulate a knowledge base search\n",
    "    knowledge_base = {\n",
    "        \"billing\": \"You can manage your billing at settings > billing\",\n",
    "        \"password\": \"To reset your password, click 'forgot password' on login\",\n",
    "        \"account\": \"You can update your account info in settings > profile\",\n",
    "    }\n",
    "    \n",
    "    for key, value in knowledge_base.items():\n",
    "        if key in query.lower():\n",
    "            return value\n",
    "    return \"No matching articles found. Please contact support.\"\n",
    "\n",
    "@tool\n",
    "def create_support_ticket(issue: str, email: str) -> str:\n",
    "    \"\"\"Create a support ticket for the user.\"\"\"\n",
    "    # Simulate ticket creation\n",
    "    ticket_id = f\"TKT-{hash(issue + email) % 10000}\"\n",
    "    return f\"Support ticket created! Ticket ID: {ticket_id}. We'll respond to {email} within 24 hours.\"\n",
    "\n",
    "@tool\n",
    "def check_account_status(email: str) -> str:\n",
    "    \"\"\"Check the status of a user account.\"\"\"\n",
    "    # Simulate account status check\n",
    "    return f\"Account {email} is active and in good standing.\"\n",
    "\n",
    "# Create a customer service agent\n",
    "customer_service_tools = [search_knowledge_base, create_support_ticket, check_account_status]\n",
    "\n",
    "# Bind these tools to the LLM\n",
    "llm_with_customer_tools = llm.bind_tools(customer_service_tools)\n",
    "\n",
    "# Create customer service agent\n",
    "customer_service_agent = create_tool_calling_agent(\n",
    "    llm_with_customer_tools, \n",
    "    customer_service_tools, \n",
    "    ChatPromptTemplate.from_messages([\n",
    "        (\"system\", \"You are a helpful customer service AI. Use available tools to help customers.\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "    ])\n",
    ")\n",
    "\n",
    "customer_service_executor = AgentExecutor(\n",
    "    agent=customer_service_agent, \n",
    "    tools=customer_service_tools, \n",
    "    verbose=True, \n",
    "    max_iterations=10\n",
    ")\n",
    "\n",
    "print(\"✓ Created specialized customer service agent with 3 custom tools\")\n",
    "print(\"  Tools available:\")\n",
    "print(\"  1. search_knowledge_base - Search documentation\")\n",
    "print(\"  2. create_support_ticket - Create support tickets\")\n",
    "print(\"  3. check_account_status - Check account status\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the customer service agent\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"CUSTOMER SERVICE AGENT TEST\")\n",
    "print(\"=\" * 60)\n",
    "result_cs = customer_service_executor.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"I forgot my password, can you help?\")]\n",
    "})\n",
    "print(\"\\nFinal Answer:\")\n",
    "print(result_cs[\"output\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
