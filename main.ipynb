{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize the ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Installing required packages...\n",
      "\n",
      "Installing langchain...\n",
      "✓ langchain installed successfully\n",
      "Installing langchain-chroma...\n",
      "✓ langchain-chroma installed successfully\n",
      "Installing langchain-openai...\n",
      "✓ langchain-openai installed successfully\n",
      "Installing langchain-core...\n",
      "✓ langchain-core installed successfully\n",
      "Installing python-dotenv...\n",
      "✓ python-dotenv installed successfully\n",
      "Installing chromadb...\n",
      "✓ chromadb installed successfully\n",
      "\n",
      "✓ All packages installed successfully!\n",
      "\n",
      "Installed packages:\n",
      "  - langchain\n",
      "  - langchain-chroma\n",
      "  - langchain-openai\n",
      "  - langchain-core\n",
      "  - python-dotenv\n",
      "  - chromadb\n"
     ]
    }
   ],
   "source": [
    "# Install all required LangChain packages\n",
    "import subprocess\n",
    "import sys\n",
    "\n",
    "packages = [\n",
    "    \"langchain\",\n",
    "    \"langchain-chroma\",\n",
    "    \"langchain-openai\",\n",
    "    \"langchain-core\",\n",
    "    \"python-dotenv\",\n",
    "    \"chromadb\"\n",
    "]\n",
    "\n",
    "print(\"Installing required packages...\\n\")\n",
    "\n",
    "for package in packages:\n",
    "    print(f\"Installing {package}...\")\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", package])\n",
    "    print(f\"✓ {package} installed successfully\")\n",
    "\n",
    "print(\"\\n✓ All packages installed successfully!\")\n",
    "print(\"\\nInstalled packages:\")\n",
    "for package in packages:\n",
    "    print(f\"  - {package}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'langchain_text_splitters'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrunnables\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RunnablePassthrough\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_openai\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m OpenAIEmbeddings, ChatOpenAI\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mlangchain_text_splitters\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CharacterTextSplitter\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# load .env file\u001b[39;00m\n\u001b[1;32m     11\u001b[0m load_dotenv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../.env\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'langchain_text_splitters'"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from dotenv import load_dotenv\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "\n",
    "# load .env file\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get Embeddings Model\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-3-large\")\n",
    "\n",
    "# Initialize ChromaDB as Vector Store\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"test_collection\",\n",
    "    embedding_function=embeddings\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the File into LangChain Documents & Save to Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in State of the Union Address File\n",
    "with open(\"2024_state_of_the_union.txt\") as f:\n",
    "    state_of_the_union = f.read()\n",
    "\n",
    "# Initialize Text Splitter\n",
    "text_splitter = CharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    length_function=len\n",
    ")\n",
    "\n",
    "# Create Documents (Chunks) From File\n",
    "texts = text_splitter.create_documents([state_of_the_union])\n",
    "\n",
    "# Save Document Chunks to Vector Store\n",
    "ids = vector_store.add_documents(texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Semantic Similarity Check with Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* And yes, my purpose tonight is to both wake up this Congress, and alert the American people that this is no ordinary moment either. \n",
      "\n",
      "Not since President Lincoln and the Civil War have freedom and democracy been under assault here at home as they are today. \n",
      "\n",
      "What makes our moment rare is that freedom and democracy are under attack, both at home and overseas, at the very same time. \n",
      "\n",
      "Overseas, Putin of Russia is on the march, invading Ukraine and sowing chaos throughout Europe and beyond. \n",
      "\n",
      "If anybody in this room thinks Putin will stop at Ukraine, I assure you, he will not. \n",
      "\n",
      "But Ukraine can stop Putin if we stand with Ukraine and provide the weapons it needs to defend itself. That is all Ukraine is asking. They are not asking for American soldiers. \n",
      "\n",
      "In fact, there are no American soldiers at war in Ukraine. And I am determined to keep it that way. \n",
      "\n",
      "But now assistance for Ukraine is being blocked by those who want us to walk away from our leadership in the world. [{}]\n",
      "\n",
      "\n",
      "* But now assistance for Ukraine is being blocked by those who want us to walk away from our leadership in the world. \n",
      "\n",
      "It wasn’t that long ago when a Republican President, Ronald Reagan, thundered, “Mr. Gorbachev, tear down this wall.” \n",
      "\n",
      "Now, my predecessor, a former Republican President, tells Putin, “Do whatever the hell you want.” \n",
      "\n",
      "A former American President actually said that, bowing down to a Russian leader. \n",
      "\n",
      "It’s outrageous. It’s dangerous. It’s unacceptable. \n",
      "\n",
      "America is a founding member of NATO the military alliance of democratic nations created after World War II to prevent war and keep the peace.  \n",
      "\n",
      "Today, we’ve made NATO stronger than ever. \n",
      "\n",
      "We welcomed Finland to the Alliance last year, and just this morning, Sweden officially joined NATO, and their Prime Minister is here tonight. \n",
      "\n",
      "Mr. Prime Minister, welcome to NATO, the strongest military alliance the world has ever known. [{}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Query the Vector Store\n",
    "results = vector_store.similarity_search(\n",
    "    'Who invaded Ukraine?',\n",
    "    k=2\n",
    ")\n",
    "\n",
    "# Print Resulting Chunks\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Document Parsing Function to String\n",
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set Chroma as the Retriever\n",
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the LLM instance\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Prompt Template\n",
    "prompt_template = \"\"\"Use the context provided to answer the user's question below. If you do not know the answer based on the context provided, tell the user that you do not know the answer to their question based on the context provided and that you are sorry.\n",
    "context: {context}\n",
    "\n",
    "question: {query}\n",
    "\n",
    "answer: \"\"\"\n",
    "\n",
    "# Create Prompt Instance from template\n",
    "custom_rag_prompt = PromptTemplate.from_template(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the RAG Chain\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"query\": RunnablePassthrough()}\n",
    "    | custom_rag_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'According to the 2024 State of the Union address, Putin of Russia invaded Ukraine.'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Query the RAG Chain\n",
    "rag_chain.invoke(\"According to the 2024 state of the union address, Who invaded Ukraine?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I'm sorry, but I do not know the answer to your question based on the context provided.\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get an I don't know from the Model\n",
    "rag_chain.invoke(\"What is the purpose of life?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
